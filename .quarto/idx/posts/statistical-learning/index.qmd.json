{"title":"Machine/Statistical Learning","markdown":{"yaml":{"title":"Machine/Statistical Learning","author":"Nduka Boika","format":"html","date":"2025-01-01","categories":["Readings and Tutorial"]},"headingText":"Lesson 1","containsRefs":false,"markdown":"\n\n**Resources:** [online resources using R](https://www.statlearning.com/resources-second-edition)\n\n[online resources using python](https://www.statlearning.com/resources-python)\n\n[deep learning](https://dmol.pub/)\n\nApplied\n\n\n## Some concepts in machine Learning\n\n### Big Data- What is it?\n\nData is data (that is, information about about a phenomenon, person or an event). When the data is voluminous(consists of many samples), has a high collection rate, is obtained from various sources etc. we can refer to this type of data as \"big data\". In the field of education and psychology, big data is not a new concept. example of such data are data collected and compiled by government educational agencies (e.g., NCES, PISA).\n\n### Statistics\n\nAfter collecting these data, we need to make sense of it using statistics. Statistics is an umbrella term used to desribe the process of collecting, collating/organizing, analyzing, and interpreting data as well as drawing conclusion to make decision about the data. Statistics also include data visualization. In the field of education and psychology, we analyze educational and psychological data, where for instance, we try to find the relationship stress and students' academic performance in mathematics. Applying statistics to analyze educational data falls under the branch of applied statistics called `Educational statistics`.\n\n::: callout-note\nThe mechanics of applied statistics and data-analytics are the same as far as i'm concerned.\n:::\n\n### Data Science\n\nThis is simply the application of scientific principles to learn from data. Pyrcz (2024) calls it the fourth paradigms for scientific discovery or data-driven scientific discovery.\n\n```{mermaid}\nflowchart LR\n  Ist_paradigmn --> experiments\n  2nd_paradigmn --> modeling\n  3rd_paradigmn --> Simulation\n  4th_paradigmn --> Data-science\n```\n\n### Machine Learning (ML)\n\nAccording to [Wikipedia](https://en.wikipedia.org/wiki/Machine_learning#Approaches); Machine learning (ML) is a field of study in [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) concerned with the development and study of `statistical algorithms` that can `learn from data and generalize to unseen data`, and thus perform tasks without explicit instructions.\n\nRedefining ML in my own terms: This is simply computers helping humans to make sense of data (using statistical algorithms) by learning from the data. Whatever is learnt from the data can then be used to make generalization to much broader or larger data (that we usually don't know).\n\nStatistical algorithm; Remember that computers helps us do calculations. As a result, they would need formulas that relates to the specific statistical methods you intend to implement to analyze your data. I think about algorithms as formulas or set of equation that the machine uses to learn how to train the model using data (usually called training data).\n\n::: border\nThere is a computer that uses algorithms (depending on the statistical method) to train models using sample data (usually called training data).\n:::\n\n### Population\n\nThe aim of inferential statistics is to make inferences about the sample data that generalizes to an unknown larger data. The data is not \"unknown\" per sey, it's just that we cannot access the data. for instance, you may be interested to know the average math performance of white students in Texas public schools. This is usually impossible because it is difficult to access the target population (assuming you are collecting the data yourself).\n\n### Sample\n\nSince we cannot access the entire population, we can access a section of the population (using appropriate sampling techniques)- the section of thge population that can accessed or measured is call sample.\n\n### Variables\n\nVariables are the specific information about a phenomena or event or person we want to know about (or measure). The variables (or vectors) together with sample size make up the dataset. Examples of variables include; gender of a person, number of dice rolled, students score on an achievement test, amount of sales made in a year etc. There are also different types of variables; two major types are discrete (take on fixed values - usually norminal) and continuous (the values are not fixed - usually interval and ratio). Other forms of variables are; independent (predictor) and dependent (outcome or response) variables. Predictors are variables that explains the outcome variable. Outcome variables are variables that we want to know more about. Predictor and outcome variables can be discrete or continuous. In ML, the predictor is the known as the input feature, while the outcome is known as the output feature in a predictive model. The model is usually accompanied by an error term.\n\n### Inference\n\nMachine Learning is all about estimating models for two purposes, inference or prediction. :::{.callout-note} Inference must precede prediction, because with inference, we want to generalize from sample to a model of the population. ::: Inference is all about making meaning of the sample data, and connecting the findings to the population. We answer questions like are the math scores between male and female students different in the population. We check this assumption and answer the question using sample data. Whatever the result is, we then generalize it to the population.\n\n### Prediction\n\nAfter making inference about the (sample) data and generalizing to the population, we can the predict future samples using the model. For instance, we can predict the maths score of female and male students in future samples.\n\n::: callout-note\nthe focus of prediction is to get the most accurate model estimates (parameter) of future samples.\n:::\n","srcMarkdownNoYaml":"\n\n**Resources:** [online resources using R](https://www.statlearning.com/resources-second-edition)\n\n[online resources using python](https://www.statlearning.com/resources-python)\n\n[deep learning](https://dmol.pub/)\n\nApplied\n\n# Lesson 1\n\n## Some concepts in machine Learning\n\n### Big Data- What is it?\n\nData is data (that is, information about about a phenomenon, person or an event). When the data is voluminous(consists of many samples), has a high collection rate, is obtained from various sources etc. we can refer to this type of data as \"big data\". In the field of education and psychology, big data is not a new concept. example of such data are data collected and compiled by government educational agencies (e.g., NCES, PISA).\n\n### Statistics\n\nAfter collecting these data, we need to make sense of it using statistics. Statistics is an umbrella term used to desribe the process of collecting, collating/organizing, analyzing, and interpreting data as well as drawing conclusion to make decision about the data. Statistics also include data visualization. In the field of education and psychology, we analyze educational and psychological data, where for instance, we try to find the relationship stress and students' academic performance in mathematics. Applying statistics to analyze educational data falls under the branch of applied statistics called `Educational statistics`.\n\n::: callout-note\nThe mechanics of applied statistics and data-analytics are the same as far as i'm concerned.\n:::\n\n### Data Science\n\nThis is simply the application of scientific principles to learn from data. Pyrcz (2024) calls it the fourth paradigms for scientific discovery or data-driven scientific discovery.\n\n```{mermaid}\nflowchart LR\n  Ist_paradigmn --> experiments\n  2nd_paradigmn --> modeling\n  3rd_paradigmn --> Simulation\n  4th_paradigmn --> Data-science\n```\n\n### Machine Learning (ML)\n\nAccording to [Wikipedia](https://en.wikipedia.org/wiki/Machine_learning#Approaches); Machine learning (ML) is a field of study in [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) concerned with the development and study of `statistical algorithms` that can `learn from data and generalize to unseen data`, and thus perform tasks without explicit instructions.\n\nRedefining ML in my own terms: This is simply computers helping humans to make sense of data (using statistical algorithms) by learning from the data. Whatever is learnt from the data can then be used to make generalization to much broader or larger data (that we usually don't know).\n\nStatistical algorithm; Remember that computers helps us do calculations. As a result, they would need formulas that relates to the specific statistical methods you intend to implement to analyze your data. I think about algorithms as formulas or set of equation that the machine uses to learn how to train the model using data (usually called training data).\n\n::: border\nThere is a computer that uses algorithms (depending on the statistical method) to train models using sample data (usually called training data).\n:::\n\n### Population\n\nThe aim of inferential statistics is to make inferences about the sample data that generalizes to an unknown larger data. The data is not \"unknown\" per sey, it's just that we cannot access the data. for instance, you may be interested to know the average math performance of white students in Texas public schools. This is usually impossible because it is difficult to access the target population (assuming you are collecting the data yourself).\n\n### Sample\n\nSince we cannot access the entire population, we can access a section of the population (using appropriate sampling techniques)- the section of thge population that can accessed or measured is call sample.\n\n### Variables\n\nVariables are the specific information about a phenomena or event or person we want to know about (or measure). The variables (or vectors) together with sample size make up the dataset. Examples of variables include; gender of a person, number of dice rolled, students score on an achievement test, amount of sales made in a year etc. There are also different types of variables; two major types are discrete (take on fixed values - usually norminal) and continuous (the values are not fixed - usually interval and ratio). Other forms of variables are; independent (predictor) and dependent (outcome or response) variables. Predictors are variables that explains the outcome variable. Outcome variables are variables that we want to know more about. Predictor and outcome variables can be discrete or continuous. In ML, the predictor is the known as the input feature, while the outcome is known as the output feature in a predictive model. The model is usually accompanied by an error term.\n\n### Inference\n\nMachine Learning is all about estimating models for two purposes, inference or prediction. :::{.callout-note} Inference must precede prediction, because with inference, we want to generalize from sample to a model of the population. ::: Inference is all about making meaning of the sample data, and connecting the findings to the population. We answer questions like are the math scores between male and female students different in the population. We check this assumption and answer the question using sample data. Whatever the result is, we then generalize it to the population.\n\n### Prediction\n\nAfter making inference about the (sample) data and generalizing to the population, we can the predict future samples using the model. For instance, we can predict the maths score of female and male students in future samples.\n\n::: callout-note\nthe focus of prediction is to get the most accurate model estimates (parameter) of future samples.\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"github","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","editor":"visual","theme":"Solar","title-block-banner":"banner.jpg","title":"Machine/Statistical Learning","author":"Nduka Boika","date":"2025-01-01","categories":["Readings and Tutorial"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}