[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "blog post",
    "section": "",
    "text": "ML_R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStructural Equation Modeling Based Meta-Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeta-analytic structural equation modeling: a primer\n\n\n\n\n\n\nZhen-Wei Dai\n\n\n\n\n\n\n\n\n\n\n\n\nMeta-analytic structural equation modeling: a primer\n\n\n\n\n\n\nZhen-Wei Dai\n\n\n\n\n\n\n\n\n\n\n\n\nMachine/Statistical Learning\n\n\n\nReadings and Tutorial\n\n\n\n\n\n\n\nNduka Boika\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMeta-analysis\n\n\n\nReadings and Tutorial\n\n\n\n\n\n\n\nNduka Boika\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCheungMetaSEM\n\n\n\nReadings and Tutorial\n\n\n\n\n\n\n\nNduka Boika\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nResearch methods\n\n\n\nReadings and Tutorial\n\n\n\n\n\n\n\nNduka Boika\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMeta-analysis\n\n\n\nR Tutorial\n\n\n\n\n\n\n\nNduka Boika\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "All qmd files/index.html",
    "href": "All qmd files/index.html",
    "title": "Nduka Boika",
    "section": "",
    "text": "I am Nduka Boika, a Ph.D. student with a deep interest in research methodology, educational statistics, and educational measurement. I am currently pursuing my doctorate at the University of North Texas in the Department of Educational Psychology, specializing in Research Methodology, Measurement, and Statistics. My academic journey is guided by my advisor, Dr. James Uanhoro."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "posts/statistical-learning/index.html",
    "href": "posts/statistical-learning/index.html",
    "title": "Machine/Statistical Learning",
    "section": "",
    "text": "Resources: online resources using R\nonline resources using python\ndeep learning\nApplied"
  },
  {
    "objectID": "posts/statistical-learning/index.html#some-concepts-in-machine-learning",
    "href": "posts/statistical-learning/index.html#some-concepts-in-machine-learning",
    "title": "Machine/Statistical Learning",
    "section": "Some concepts in machine Learning",
    "text": "Some concepts in machine Learning\n\nBig Data- What is it?\nData is data (that is, information about about a phenomenon, person or an event). When the data is voluminous(consists of many samples), has a high collection rate, is obtained from various sources etc. we can refer to this type of data as “big data”. In the field of education and psychology, big data is not a new concept. example of such data are data collected and compiled by government educational agencies (e.g., NCES, PISA).\n\n\nStatistics\nAfter collecting these data, we need to make sense of it using statistics. Statistics is an umbrella term used to desribe the process of collecting, collating/organizing, analyzing, and interpreting data as well as drawing conclusion to make decision about the data. Statistics also include data visualization. In the field of education and psychology, we analyze educational and psychological data, where for instance, we try to find the relationship stress and students’ academic performance in mathematics. Applying statistics to analyze educational data falls under the branch of applied statistics called Educational statistics.\n\n\n\n\n\n\nNote\n\n\n\nThe mechanics of applied statistics and data-analytics are the same as far as i’m concerned.\n\n\n\n\nData Science\nThis is simply the application of scientific principles to learn from data. Pyrcz (2024) calls it the fourth paradigms for scientific discovery or data-driven scientific discovery.\n\n\n\n\n\nflowchart LR\n  Ist_paradigmn --&gt; experiments\n  2nd_paradigmn --&gt; modeling\n  3rd_paradigmn --&gt; Simulation\n  4th_paradigmn --&gt; Data-science\n\n\n\n\n\n\n\n\nMachine Learning (ML)\nAccording to Wikipedia; Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.\nRedefining ML in my own terms: This is simply computers helping humans to make sense of data (using statistical algorithms) by learning from the data. Whatever is learnt from the data can then be used to make generalization to much broader or larger data (that we usually don’t know).\nStatistical algorithm; Remember that computers helps us do calculations. As a result, they would need formulas that relates to the specific statistical methods you intend to implement to analyze your data. I think about algorithms as formulas or set of equation that the machine uses to learn how to train the model using data (usually called training data).\n\nThere is a computer that uses algorithms (depending on the statistical method) to train models using sample data (usually called training data).\n\n\n\nPopulation\nThe aim of inferential statistics is to make inferences about the sample data that generalizes to an unknown larger data. The data is not “unknown” per sey, it’s just that we cannot access the data. for instance, you may be interested to know the average math performance of white students in Texas public schools. This is usually impossible because it is difficult to access the target population (assuming you are collecting the data yourself).\n\n\nSample\nSince we cannot access the entire population, we can access a section of the population (using appropriate sampling techniques)- the section of thge population that can accessed or measured is call sample.\n\n\nVariables\nVariables are the specific information about a phenomena or event or person we want to know about (or measure). The variables (or vectors) together with sample size make up the dataset. Examples of variables include; gender of a person, number of dice rolled, students score on an achievement test, amount of sales made in a year etc. There are also different types of variables; two major types are discrete (take on fixed values - usually norminal) and continuous (the values are not fixed - usually interval and ratio). Other forms of variables are; independent (predictor) and dependent (outcome or response) variables. Predictors are variables that explains the outcome variable. Outcome variables are variables that we want to know more about. Predictor and outcome variables can be discrete or continuous. In ML, the predictor is the known as the input feature, while the outcome is known as the output feature in a predictive model. The model is usually accompanied by an error term.\n\n\nInference\nMachine Learning is all about estimating models for two purposes, inference or prediction. :::{.callout-note} Inference must precede prediction, because with inference, we want to generalize from sample to a model of the population. ::: Inference is all about making meaning of the sample data, and connecting the findings to the population. We answer questions like are the math scores between male and female students different in the population. We check this assumption and answer the question using sample data. Whatever the result is, we then generalize it to the population.\n\n\nPrediction\nAfter making inference about the (sample) data and generalizing to the population, we can the predict future samples using the model. For instance, we can predict the maths score of female and male students in future samples.\n\n\n\n\n\n\nNote\n\n\n\nthe focus of prediction is to get the most accurate model estimates (parameter) of future samples."
  },
  {
    "objectID": "posts/meta-analysis/Meta-analysis.html",
    "href": "posts/meta-analysis/Meta-analysis.html",
    "title": "Meta-analysis",
    "section": "",
    "text": "Resources: meta-guide"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nduka Boika",
    "section": "",
    "text": "Nduka Boika is a seasoned learner with interest in Research Methodology, Educational Statistics, and Eductional Measurement. He is currently pursuing a Ph.D at University of North Texas in the Department of Educational Psychology with a focus on Research Methodology, Measurement and Statistics. His thoughts and journey will be captured herein."
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html",
    "href": "posts/meta-analysis/CheungMetaSEM.html",
    "title": "CheungMetaSEM",
    "section": "",
    "text": "Meta-analysis combines and synthesizes findings with statistical model. So, we are basically taking all the studies we have systematically reviewed, extract the results, and quantitaively analyze the data or the result. By result we mean the effect sizes.\nEffect-sizes and variance components are the building block of meta-analysis. “Effect-sizes” must satisfy the three conditions below: a. strength - It must tell the magnitude of the relationship or differences between the variables of interest in the model. b. direction - It must tell if the relationship or differences between the variables in the model is positive or negative. c. independence of direction.\n\\(R^2, \\Delta R^2, \\eta^2, \\omega^2\\) are not considered effect sizes because they don’t indicate the direction of the magnitude. \\(\\hat{\\beta}, \\rho , \\Delta \\mu\\), odds ratio can be classified as effect sizes.\nIn meta-analytic SEM, raw correlation coefficients \\(y_r = r\\) are used and a sampling variance component (\\(SE^2_r\\)) = \\((1 - r^2)^2/n-1\\)\nThe existing differences in population and observed effect-sizes between studies is termed heterogeneity of effect-sizes (\\(\\tau^2\\)). (\\(\\tau^2\\)) cannot be compared across effect-sizes because it is specific to a particular effect-size.\nWe can quantify the (\\(\\tau^2\\)) using one of the following formulas below: - \\(I^2 = Q - (K - 1)/ Q\\); where \\(I^2\\) is -ve then it is truncated to zero (0). ?? what is Q and K. - \\(I^2 = \\hat{\\tau^2}/(\\hat{\\tau^2} + \\hat{v_i})\\) ; where \\(\\hat{v_i}\\) = average sampling variance.\nInterpretation: this is the proportion of total variation due to differences between studies (heterogeneity)- ratio of between studies variances and total variance. (just like in multi-level modeling).\nRule of thumb: $I^2 = $ 25%, 50%, and 75% are considered low, moderate, and high heterogeneity respectively. As sample size increases, \\(\\hat{v_i}\\) becomes smaller and \\(I^2\\) approaches 1.\n\n\n\n\n\n\nNote\n\n\n\n\\(I^2\\) = absolute measure of heterogeneity, and \\(I^2\\) = relative measure of heterogeneity dependent on \\(\\hat{v_i}\\). Always report both indices.\n\n\nConfidence Intervals\nGenerally in Meta Analysis, there are two models:\n\nFixed-effects model:\n\n\nThe population effect-sizes across all studies are assumed to be equal or the same. That is, each of the studies have the same population effect-size. In other words, there is a true effect (in the population, but it is the same for all individual study).\nThe differences in the observed effect-size is simply due to random (sampling) error attached to each individual studies with a variance of v.\nWe can only generalize the finding to the other findings related to the studies in the meta-analysis (that is., studies that have the same research design, measure the same number of variables, and the same samples). In other words, we cannot generalize the findings from the meta-analysis in FE beyond the studies (to a general population).\n\n\nRandom-effects model\n\n\nPopulation effect-sizes can be different for individual studies.\nThe differences in the observed effect-sizes are due to a combination random (sampling) error with a variance of v (the difference between the observed and population effect-size) and the True difference (or variance) that is., the difference between the studies effect sizes.\nFindings from the meta analysis can be generalized beyond the studies in the meta-analysis."
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#some-notes-on-meta-analytic-sem-masem",
    "href": "posts/meta-analysis/CheungMetaSEM.html#some-notes-on-meta-analytic-sem-masem",
    "title": "CheungMetaSEM",
    "section": "",
    "text": "Meta-analysis combines and synthesizes findings with statistical model. So, we are basically taking all the studies we have systematically reviewed, extract the results, and quantitaively analyze the data or the result. By result we mean the effect sizes.\nEffect-sizes and variance components are the building block of meta-analysis. “Effect-sizes” must satisfy the three conditions below: a. strength - It must tell the magnitude of the relationship or differences between the variables of interest in the model. b. direction - It must tell if the relationship or differences between the variables in the model is positive or negative. c. independence of direction.\n\\(R^2, \\Delta R^2, \\eta^2, \\omega^2\\) are not considered effect sizes because they don’t indicate the direction of the magnitude. \\(\\hat{\\beta}, \\rho , \\Delta \\mu\\), odds ratio can be classified as effect sizes.\nIn meta-analytic SEM, raw correlation coefficients \\(y_r = r\\) are used and a sampling variance component (\\(SE^2_r\\)) = \\((1 - r^2)^2/n-1\\)\nThe existing differences in population and observed effect-sizes between studies is termed heterogeneity of effect-sizes (\\(\\tau^2\\)). (\\(\\tau^2\\)) cannot be compared across effect-sizes because it is specific to a particular effect-size.\nWe can quantify the (\\(\\tau^2\\)) using one of the following formulas below: - \\(I^2 = Q - (K - 1)/ Q\\); where \\(I^2\\) is -ve then it is truncated to zero (0). ?? what is Q and K. - \\(I^2 = \\hat{\\tau^2}/(\\hat{\\tau^2} + \\hat{v_i})\\) ; where \\(\\hat{v_i}\\) = average sampling variance.\nInterpretation: this is the proportion of total variation due to differences between studies (heterogeneity)- ratio of between studies variances and total variance. (just like in multi-level modeling).\nRule of thumb: $I^2 = $ 25%, 50%, and 75% are considered low, moderate, and high heterogeneity respectively. As sample size increases, \\(\\hat{v_i}\\) becomes smaller and \\(I^2\\) approaches 1.\n\n\n\n\n\n\nNote\n\n\n\n\\(I^2\\) = absolute measure of heterogeneity, and \\(I^2\\) = relative measure of heterogeneity dependent on \\(\\hat{v_i}\\). Always report both indices.\n\n\nConfidence Intervals\nGenerally in Meta Analysis, there are two models:\n\nFixed-effects model:\n\n\nThe population effect-sizes across all studies are assumed to be equal or the same. That is, each of the studies have the same population effect-size. In other words, there is a true effect (in the population, but it is the same for all individual study).\nThe differences in the observed effect-size is simply due to random (sampling) error attached to each individual studies with a variance of v.\nWe can only generalize the finding to the other findings related to the studies in the meta-analysis (that is., studies that have the same research design, measure the same number of variables, and the same samples). In other words, we cannot generalize the findings from the meta-analysis in FE beyond the studies (to a general population).\n\n\nRandom-effects model\n\n\nPopulation effect-sizes can be different for individual studies.\nThe differences in the observed effect-sizes are due to a combination random (sampling) error with a variance of v (the difference between the observed and population effect-size) and the True difference (or variance) that is., the difference between the studies effect sizes.\nFindings from the meta analysis can be generalized beyond the studies in the meta-analysis."
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#replicating-cheungs-example",
    "href": "posts/meta-analysis/CheungMetaSEM.html#replicating-cheungs-example",
    "title": "CheungMetaSEM",
    "section": "Replicating Cheungs example",
    "text": "Replicating Cheungs example"
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#univariate-approach",
    "href": "posts/meta-analysis/CheungMetaSEM.html#univariate-approach",
    "title": "CheungMetaSEM",
    "section": "Univariate approach",
    "text": "Univariate approach\n\nRandom-effects modelFixed-effects modelMixed-effects model\n\n\n\n\nCode\n## Load the library\nlibrary(metaSEM)\n\n\nLoading required package: OpenMx\n\n\nOpenMx may run faster if it is compiled to take advantage of multiple cores.\n\n\n\"SLSQP\" is set as the default optimizer in OpenMx.\n\n\nmxOption(NULL, \"Gradient algorithm\") is set at \"central\".\n\n\nmxOption(NULL, \"Optimality tolerance\") is set at \"6.3e-14\".\n\n\nmxOption(NULL, \"Gradient iterations\") is set at \"2\".\n\n\nCode\nhead(Becker83)\n\n\n  study    di   vi percentage items\n1     1 -0.33 0.03         25     2\n2     2  0.07 0.03         25     2\n3     3 -0.30 0.02         50     2\n4     4  0.35 0.02        100    38\n5     5  0.69 0.07        100    30\n6     6  0.81 0.22        100    45\n\n\nCode\n## Random-effects meta-analysis with ML\nsummary(meta(y=di, v=vi, data=Becker83))\n\n\n\nCall:\nmeta(y = di, v = vi, data = Becker83)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n            Estimate Std.Error    lbound    ubound z value Pr(&gt;|z|)\nIntercept1  0.174734  0.113378 -0.047482  0.396950  1.5412   0.1233\nTau2_1_1    0.077376  0.054108 -0.028674  0.183426  1.4300   0.1527\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nHeterogeneity indices (based on the estimated Tau2):\n                             Estimate\nIntercept1: I2 (Q statistic)   0.6718\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 2\nDegrees of freedom: 8\n-2 log likelihood: 7.928307 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Fixed-effects meta-analysis by fixing the heterogeneity variance at 0\nsummary( meta(y=di, v=vi, data=Becker83, RE.constraints=0) )\n\n\n\nCall:\nmeta(y = di, v = vi, data = Becker83, RE.constraints = 0)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n            Estimate Std.Error    lbound    ubound z value Pr(&gt;|z|)  \nIntercept1  0.100640  0.060510 -0.017957  0.219237  1.6632  0.09627 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nHeterogeneity indices (based on the estimated Tau2):\n                             Estimate\nIntercept1: I2 (Q statistic)        0\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 1\nDegrees of freedom: 9\n-2 log likelihood: 17.86043 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Mixed-effects meta-analysis with \"log(items)\" as the predictor\nsummary( meta(y=di, v=vi, x=log(items), data=Becker83) ) \n\n\n\nCall:\nmeta(y = di, v = vi, x = log(items), data = Becker83)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n              Estimate   Std.Error      lbound      ubound z value  Pr(&gt;|z|)\nIntercept1 -3.2015e-01  1.0981e-01 -5.3539e-01 -1.0492e-01 -2.9154  0.003552\nSlope1_1    2.1088e-01  4.5084e-02  1.2251e-01  2.9924e-01  4.6774 2.905e-06\nTau2_1_1    1.0000e-10  2.0095e-02 -3.9386e-02  3.9386e-02  0.0000  1.000000\n              \nIntercept1 ** \nSlope1_1   ***\nTau2_1_1      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nExplained variances (R2):\n                           y1\nTau2 (no predictor)    0.0774\nTau2 (with predictors) 0.0000\nR2                     1.0000\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 3\nDegrees of freedom: 7\n-2 log likelihood: -4.208024 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#getting-up",
    "href": "posts/Presentation slides/paper1_presentation.html#getting-up",
    "title": "paper1_presentation",
    "section": "Getting up",
    "text": "Getting up\n\nTurn off alarm\nGet out of bed"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#going-to-sleep",
    "href": "posts/Presentation slides/paper1_presentation.html#going-to-sleep",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Going to sleep",
    "text": "Going to sleep\n\nGet in bed\nCount sheep"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#breakfast",
    "href": "posts/Presentation slides/paper1_presentation.html#breakfast",
    "title": "paper1_presentation",
    "section": "Breakfast",
    "text": "Breakfast\n\nEat eggs\nDrink coffee"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#dinner",
    "href": "posts/Presentation slides/paper1_presentation.html#dinner",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Dinner",
    "text": "Dinner\n\nEat spaghetti\nDrink wine"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#background",
    "href": "posts/Presentation slides/paper1_presentation.html#background",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Background",
    "text": "Background\n\nMeta-analytic SEM (MASEM) is the integration of two methods: Meta-analysis and Structural equation modeling (SEM).\nWith MASEM, we can explain the relationship between groups of variables across several studies.\nMASEM can be applied in different fields including psychology, education, medicine, …\nAccording to the author, MASEM is not yet very popular thus the need to write the primer."
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#introduction-to-meta-analysis-ma",
    "href": "posts/Presentation slides/paper1_presentation.html#introduction-to-meta-analysis-ma",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Introduction to meta-analysis (MA)",
    "text": "Introduction to meta-analysis (MA)\n\nMA refers to a set of statistical procedure used to synthesize research findings (quantitative data) from multiple studies for the purpose of obtaining a conclusion about the research question.\nAccording to Glass, whether the analysis is referred to as a primary, secondary or meta-analysis dependents on how the data was analyzed.\nWhen primary data collected (first time) by the researcher for a particular study and is analyzed - primary analysis.\nWhen the primary data is re-analyzed by another researcher for a study, the data then becomes a secondary data and the analysis is a secondary analysis.\nmeta-analysis integrates a number of independent studies and combines these independent studies by statistical means to get a comprehensive result.\nSmith and Glass were the earliest psychologist in the field of social science to employ meta-analysis. They analyzed 375 research results on whether psychotherapy was effective for patients. They concluded that almost no difference existed in the effects of different psychotherapy methods - effective."
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#introduction-to-sem",
    "href": "posts/Presentation slides/paper1_presentation.html#introduction-to-sem",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Introduction to SEM",
    "text": "Introduction to SEM\n\nSEM is a statistical method that integrates regression analysis, factor analysis and path analysis.\npath analysis was proposed by Wright in 1920, Spearman put forward factor analysis in 1904\nPath analysis examines the complicated relationship between observed variables. So path analysis can be regarded as a special SEM analysis.\nSEM is a confirmatory statistical method that thrives on rigorous theoretical support in the form of an hypothesized model. With SEM the hypothesized model is fit to data\nCompared with path analysis, SEM can simultaneously estimate the measurement indicators, latent variables, error of measurement indicators, and validity of measurement.\nSEM can be conducted if;\n\nthe data is multivariate normal\nthe sample size and the covariance matrix (that shows the relationship between variables) is provided."
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#slide-title",
    "href": "posts/Presentation slides/paper1_presentation.html#slide-title",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Slide Title",
    "text": "Slide Title\nSlide content\n\n\nSome additional commentary of more peripheral interest."
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#slide-title-1",
    "href": "posts/Presentation slides/paper1_presentation.html#slide-title-1",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Slide Title",
    "text": "Slide Title\n\nGreen 1\nBrown\nPurple\n\n\n\n\n\n\n\n\n\n\n\n\nTab ATab B\n\n\n\n\n\n\n\n\n\n\n\n\n\nContent for Tab B\n\n\n\n\nSome additional commentary of more peripheral interest.\nA footnote"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#slide-title-1-output",
    "href": "posts/Presentation slides/paper1_presentation.html#slide-title-1-output",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Slide Title",
    "text": "Slide Title"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#section-1",
    "href": "posts/Presentation slides/paper1_presentation.html#section-1",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "",
    "text": "(A slide with no title)"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#section-2",
    "href": "posts/Presentation slides/paper1_presentation.html#section-2",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "",
    "text": "(Another slide with no title)"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#slide-title-2",
    "href": "posts/Presentation slides/paper1_presentation.html#slide-title-2",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Slide Title",
    "text": "Slide Title"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#slide-title-3",
    "href": "posts/Presentation slides/paper1_presentation.html#slide-title-3",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Slide Title",
    "text": "Slide Title\n\n\n\nMeta-analytic structural equation modeling: a primer"
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#tssem-approach",
    "href": "posts/meta-analysis/CheungMetaSEM.html#tssem-approach",
    "title": "CheungMetaSEM",
    "section": "TSSEM approach",
    "text": "TSSEM approach\n\nRandom-effects modelFixed-effects modelMixed-effects modelHandling missing covariates with FIML\n\n\n\n\nCode\n## Load the library\nlibrary(metaSEM)\nhead(Becker83)\n\n\n  study    di   vi percentage items\n1     1 -0.33 0.03         25     2\n2     2  0.07 0.03         25     2\n3     3 -0.30 0.02         50     2\n4     4  0.35 0.02        100    38\n5     5  0.69 0.07        100    30\n6     6  0.81 0.22        100    45\n\n\nCode\n## Random-effects meta-analysis with ML\nsummary(meta(y=di, v=vi, data=Becker83))\n\n\n\nCall:\nmeta(y = di, v = vi, data = Becker83)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n            Estimate Std.Error    lbound    ubound z value Pr(&gt;|z|)\nIntercept1  0.174734  0.113378 -0.047482  0.396950  1.5412   0.1233\nTau2_1_1    0.077376  0.054108 -0.028674  0.183426  1.4300   0.1527\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nHeterogeneity indices (based on the estimated Tau2):\n                             Estimate\nIntercept1: I2 (Q statistic)   0.6718\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 2\nDegrees of freedom: 8\n-2 log likelihood: 7.928307 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Fixed-effects meta-analysis by fixing the heterogeneity variance at 0\nsummary( meta(y=di, v=vi, data=Becker83, RE.constraints=0) )\n\n\n\nCall:\nmeta(y = di, v = vi, data = Becker83, RE.constraints = 0)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n            Estimate Std.Error    lbound    ubound z value Pr(&gt;|z|)  \nIntercept1  0.100640  0.060510 -0.017957  0.219237  1.6632  0.09627 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nHeterogeneity indices (based on the estimated Tau2):\n                             Estimate\nIntercept1: I2 (Q statistic)        0\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 1\nDegrees of freedom: 9\n-2 log likelihood: 17.86043 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Mixed-effects meta-analysis with \"log(items)\" as the predictor\nsummary( meta(y=di, v=vi, x=log(items), data=Becker83) ) \n\n\n\nCall:\nmeta(y = di, v = vi, x = log(items), data = Becker83)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n              Estimate   Std.Error      lbound      ubound z value  Pr(&gt;|z|)\nIntercept1 -3.2015e-01  1.0981e-01 -5.3539e-01 -1.0492e-01 -2.9154  0.003552\nSlope1_1    2.1088e-01  4.5084e-02  1.2251e-01  2.9924e-01  4.6774 2.905e-06\nTau2_1_1    1.0000e-10  2.0095e-02 -3.9386e-02  3.9386e-02  0.0000  1.000000\n              \nIntercept1 ** \nSlope1_1   ***\nTau2_1_1      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nExplained variances (R2):\n                           y1\nTau2 (no predictor)    0.0774\nTau2 (with predictors) 0.0000\nR2                     1.0000\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 3\nDegrees of freedom: 7\n-2 log likelihood: -4.208024 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Sample data from Tenenbaum and Leaper (2002, Table 1).\nTenenbaum02 &lt;- Tenenbaum02[, c(\"r\", \"v\", \"Offspring_age\", \"Year_pub\")]\n\n## Set seed for reproducibility\nset.seed(1234567)\n\n## Let's drop 40% in Offspring_age\nmissing_per &lt;- 0.4\n\n## MCAR\nindex &lt;- round(nrow(Tenenbaum02)*missing_per)\nindex &lt;- rep(c(TRUE, FALSE), times=c(index, nrow(Tenenbaum02)-index))\nindex &lt;- sample(index)\nmy.MCAR &lt;- Tenenbaum02\nmy.MCAR[index, \"Offspring_age\"] &lt;- NA\nmy.MCAR$Offspring_age &lt;- scale(my.MCAR$Offspring_age, scale=FALSE)\nmy.MCAR$Year_pub &lt;- scale(my.MCAR$Year_pub, scale=FALSE)\n\nmy.MCAR\n\n\n       r            v Offspring_age     Year_pub\n1   0.12 0.0029084053            NA  -4.91666667\n2  -0.08 0.0099721309   -48.3448276   3.08333333\n3  -0.05 0.0103646484   -72.3448276  -7.91666667\n4  -0.08 0.0094022949   -69.3448276  -8.91666667\n5   0.15 0.0013089127   209.6551724  -1.91666667\n6   0.12 0.0404753067   -60.3448276   0.08333333\n7   0.17 0.0052101393            NA   0.08333333\n8   0.34 0.0181898456   107.6551724  -3.91666667\n9  -0.01 0.0020238867            NA   5.08333333\n10  0.33 0.0048124801            NA  10.08333333\n11  0.40 0.0147000000   -93.3448276   1.08333333\n12  0.30 0.0138016667   -90.3448276   4.08333333\n13  0.07 0.0162331805   -57.3448276  13.08333333\n14 -0.02 0.0099920016            NA  -2.91666667\n15  0.19 0.0092910321    -5.3448276  -2.91666667\n16  0.15 0.0006964331    23.6551724  11.08333333\n17  0.19 0.0032148900   -18.3448276   7.08333333\n18  0.02 0.0057097152   -30.3448276  -7.91666667\n19  0.47 0.0085492508            NA  -6.91666667\n20  0.19 0.0046455161     5.6551724  11.08333333\n21  0.33 0.0124071752            NA  -7.91666667\n22  0.06 0.0157589359   -36.3448276  -7.91666667\n23  0.05 0.0033166875            NA   2.08333333\n24  0.24 0.0024877248            NA   5.08333333\n25  0.14 0.0123228738            NA -10.91666667\n26 -0.02 0.0285485760            NA   5.08333333\n27  0.28 0.0066877682            NA  11.08333333\n28  0.14 0.0034825513    35.6551724   9.08333333\n29  0.27 0.0245575546   -42.3448276  -3.91666667\n30  0.38 0.0140779108   -12.3448276 -10.91666667\n31  0.52 0.0212926464            NA  -5.91666667\n32  0.66 0.0127418944    23.6551724  -5.91666667\n33  0.36 0.0303038464    23.6551724  -5.91666667\n34  0.21 0.0042698356    11.6551724  10.08333333\n35  0.19 0.0042231964    11.6551724  10.08333333\n36  0.14 0.0184843108            NA -12.91666667\n37  0.36 0.0102377859    95.6551724  -7.91666667\n38  0.09 0.0006314927    23.6551724  11.08333333\n39  0.16 0.0053946327            NA  13.08333333\n40 -0.07 0.0319427100            NA  -0.91666667\n41  0.36 0.0140295585    89.6551724  -8.91666667\n42  0.36 0.0008270700    95.6551724  -4.91666667\n43  0.22 0.0238300674    -0.3448276   8.08333333\n44  0.04 0.0066899501   -72.3448276   7.08333333\n45  0.06 0.0146001906            NA  -8.91666667\n46  0.41 0.0150447307            NA  -3.91666667\n47  0.04 0.0140394727            NA  -3.91666667\n48  0.23 0.0067954425   -48.3448276   2.08333333\n\n\nCode\nfit &lt;- metaFIML(y=r, v=v, x=Offspring_age, av=Year_pub, data=my.MCAR)\nsummary(fit)\n\n\n\nCall:\nmetaFIML(y = r, v = v, x = Offspring_age, av = Year_pub, data = my.MCAR)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n              Estimate   Std.Error      lbound      ubound z value  Pr(&gt;|z|)\nTau2_1_1    1.2136e-02  4.5317e-03  3.2543e-03  2.1018e-02  2.6781 0.0074043\nCovX1_X1    4.6116e+03  1.2071e+03  2.2456e+03  6.9775e+03  3.8203 0.0001333\nCovX2_X1   -6.0799e+01  9.3469e+01 -2.4399e+02  1.2240e+02 -0.6505 0.5153883\nCovX2_X2    5.7118e+01  1.1659e+01  3.4267e+01  7.9970e+01  4.8990 9.633e-07\nCovX2_Y1   -1.3300e-01  1.6016e-01 -4.4691e-01  1.8090e-01 -0.8305 0.4062841\nSlope1_1    6.8319e-04  3.5911e-04 -2.0648e-05  1.3870e-03  1.9025 0.0571101\nIntercept1  1.8420e-01  2.1886e-02  1.4130e-01  2.2709e-01  8.4163 &lt; 2.2e-16\nMeanX1      7.7305e-02  1.2402e+01 -2.4230e+01  2.4385e+01  0.0062 0.9950265\nMeanX2     -5.7253e-08  1.0908e+00 -2.1380e+00  2.1380e+00  0.0000 1.0000000\n              \nTau2_1_1   ** \nCovX1_X1   ***\nCovX2_X1      \nCovX2_X2   ***\nCovX2_Y1      \nSlope1_1   .  \nIntercept1 ***\nMeanX1        \nMeanX2        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nQ statistic on the homogeneity of effect sizes: 179.0075\nDegrees of freedom of the Q statistic: 47\nP value of the Q statistic: 0\n\nExplained variances (R2):\n                           y1\nTau2 (no predictor)    0.0142\nTau2 (with predictors) 0.0121\nR2                     0.1474\n\nNumber of studies (or clusters): 48\nNumber of observed statistics: 9\nNumber of estimated parameters: 9\nDegrees of freedom: 0\n-2 log likelihood: 613.2553 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)"
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#tssem",
    "href": "posts/meta-analysis/CheungMetaSEM.html#tssem",
    "title": "CheungMetaSEM",
    "section": "TSSEM",
    "text": "TSSEM\n\nRandom-effects modelFixed-effects modelMixed-effects model\n\n\n\n\nCode\n## Load the library\nlibrary(metaSEM)\nhead(Becker83)\n\n\n  study    di   vi percentage items\n1     1 -0.33 0.03         25     2\n2     2  0.07 0.03         25     2\n3     3 -0.30 0.02         50     2\n4     4  0.35 0.02        100    38\n5     5  0.69 0.07        100    30\n6     6  0.81 0.22        100    45\n\n\nCode\n## Random-effects meta-analysis with ML\nsummary(meta(y=di, v=vi, data=Becker83))\n\n\n\nCall:\nmeta(y = di, v = vi, data = Becker83)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n            Estimate Std.Error    lbound    ubound z value Pr(&gt;|z|)\nIntercept1  0.174734  0.113378 -0.047482  0.396950  1.5412   0.1233\nTau2_1_1    0.077376  0.054108 -0.028674  0.183426  1.4300   0.1527\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nHeterogeneity indices (based on the estimated Tau2):\n                             Estimate\nIntercept1: I2 (Q statistic)   0.6718\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 2\nDegrees of freedom: 8\n-2 log likelihood: 7.928307 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Fixed-effects meta-analysis by fixing the heterogeneity variance at 0\nsummary( meta(y=di, v=vi, data=Becker83, RE.constraints=0) )\n\n\n\nCall:\nmeta(y = di, v = vi, data = Becker83, RE.constraints = 0)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n            Estimate Std.Error    lbound    ubound z value Pr(&gt;|z|)  \nIntercept1  0.100640  0.060510 -0.017957  0.219237  1.6632  0.09627 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nHeterogeneity indices (based on the estimated Tau2):\n                             Estimate\nIntercept1: I2 (Q statistic)        0\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 1\nDegrees of freedom: 9\n-2 log likelihood: 17.86043 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Mixed-effects meta-analysis with \"log(items)\" as the predictor\nsummary( meta(y=di, v=vi, x=log(items), data=Becker83) ) \n\n\n\nCall:\nmeta(y = di, v = vi, x = log(items), data = Becker83)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n              Estimate   Std.Error      lbound      ubound z value  Pr(&gt;|z|)\nIntercept1 -3.2015e-01  1.0981e-01 -5.3539e-01 -1.0492e-01 -2.9154  0.003552\nSlope1_1    2.1088e-01  4.5084e-02  1.2251e-01  2.9924e-01  4.6774 2.905e-06\nTau2_1_1    1.0000e-10  2.0095e-02 -3.9386e-02  3.9386e-02  0.0000  1.000000\n              \nIntercept1 ** \nSlope1_1   ***\nTau2_1_1      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nExplained variances (R2):\n                           y1\nTau2 (no predictor)    0.0774\nTau2 (with predictors) 0.0000\nR2                     1.0000\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 3\nDegrees of freedom: 7\n-2 log likelihood: -4.208024 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)"
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#tssem-approach-1",
    "href": "posts/meta-analysis/CheungMetaSEM.html#tssem-approach-1",
    "title": "CheungMetaSEM",
    "section": "TSSEM approach",
    "text": "TSSEM approach\n\nRandom-effects modelFixed-effects modelMixed-effects modelHandling missing covariates\n\n\n\n\nCode\n## Load the library\nlibrary(metaSEM)\nhead(Becker83)\n\n\n  study    di   vi percentage items\n1     1 -0.33 0.03         25     2\n2     2  0.07 0.03         25     2\n3     3 -0.30 0.02         50     2\n4     4  0.35 0.02        100    38\n5     5  0.69 0.07        100    30\n6     6  0.81 0.22        100    45\n\n\nCode\n## Random-effects meta-analysis with ML\nsummary(meta(y=di, v=vi, data=Becker83))\n\n\n\nCall:\nmeta(y = di, v = vi, data = Becker83)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n            Estimate Std.Error    lbound    ubound z value Pr(&gt;|z|)\nIntercept1  0.174734  0.113378 -0.047482  0.396950  1.5412   0.1233\nTau2_1_1    0.077376  0.054108 -0.028674  0.183426  1.4300   0.1527\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nHeterogeneity indices (based on the estimated Tau2):\n                             Estimate\nIntercept1: I2 (Q statistic)   0.6718\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 2\nDegrees of freedom: 8\n-2 log likelihood: 7.928307 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Fixed-effects meta-analysis by fixing the heterogeneity variance at 0\nsummary( meta(y=di, v=vi, data=Becker83, RE.constraints=0) )\n\n\n\nCall:\nmeta(y = di, v = vi, data = Becker83, RE.constraints = 0)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n            Estimate Std.Error    lbound    ubound z value Pr(&gt;|z|)  \nIntercept1  0.100640  0.060510 -0.017957  0.219237  1.6632  0.09627 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nHeterogeneity indices (based on the estimated Tau2):\n                             Estimate\nIntercept1: I2 (Q statistic)        0\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 1\nDegrees of freedom: 9\n-2 log likelihood: 17.86043 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Mixed-effects meta-analysis with \"log(items)\" as the predictor\nsummary( meta(y=di, v=vi, x=log(items), data=Becker83) ) \n\n\n\nCall:\nmeta(y = di, v = vi, x = log(items), data = Becker83)\n\n95% confidence intervals: z statistic approximation (robust=FALSE)\nCoefficients:\n              Estimate   Std.Error      lbound      ubound z value  Pr(&gt;|z|)\nIntercept1 -3.2015e-01  1.0981e-01 -5.3539e-01 -1.0492e-01 -2.9154  0.003552\nSlope1_1    2.1088e-01  4.5084e-02  1.2251e-01  2.9924e-01  4.6774 2.905e-06\nTau2_1_1    1.0000e-10  2.0095e-02 -3.9386e-02  3.9386e-02  0.0000  1.000000\n              \nIntercept1 ** \nSlope1_1   ***\nTau2_1_1      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nQ statistic on the homogeneity of effect sizes: 30.64949\nDegrees of freedom of the Q statistic: 9\nP value of the Q statistic: 0.0003399239\n\nExplained variances (R2):\n                           y1\nTau2 (no predictor)    0.0774\nTau2 (with predictors) 0.0000\nR2                     1.0000\n\nNumber of studies (or clusters): 10\nNumber of observed statistics: 10\nNumber of estimated parameters: 3\nDegrees of freedom: 7\n-2 log likelihood: -4.208024 \nOpenMx status1: 0 (\"0\" or \"1\": The optimization is considered fine.\nOther values may indicate problems.)\n\n\n\n\n\n\nCode\n## Sample data from Tenenbaum and Leaper (2002, Table 1).\nTenenbaum02 &lt;- Tenenbaum02[, c(\"r\", \"v\", \"Offspring_age\", \"Year_pub\")]\n\n## Set seed for reproducibility\nset.seed(1234567)\n\n## Let's drop 40% in Offspring_age\nmissing_per &lt;- 0.4\n\n## MCAR\nindex &lt;- round(nrow(Tenenbaum02)*missing_per)\nindex &lt;- rep(c(TRUE, FALSE), times=c(index, nrow(Tenenbaum02)-index))\nindex &lt;- sample(index)\nmy.MCAR &lt;- Tenenbaum02\nmy.MCAR[index, \"Offspring_age\"] &lt;- NA\nmy.MCAR$Offspring_age &lt;- scale(my.MCAR$Offspring_age, scale=FALSE)\nmy.MCAR$Year_pub &lt;- scale(my.MCAR$Year_pub, scale=FALSE)\n\nmy.MCAR\n\n\n       r            v Offspring_age     Year_pub\n1   0.12 0.0029084053            NA  -4.91666667\n2  -0.08 0.0099721309   -48.3448276   3.08333333\n3  -0.05 0.0103646484   -72.3448276  -7.91666667\n4  -0.08 0.0094022949   -69.3448276  -8.91666667\n5   0.15 0.0013089127   209.6551724  -1.91666667\n6   0.12 0.0404753067   -60.3448276   0.08333333\n7   0.17 0.0052101393            NA   0.08333333\n8   0.34 0.0181898456   107.6551724  -3.91666667\n9  -0.01 0.0020238867            NA   5.08333333\n10  0.33 0.0048124801            NA  10.08333333\n11  0.40 0.0147000000   -93.3448276   1.08333333\n12  0.30 0.0138016667   -90.3448276   4.08333333\n13  0.07 0.0162331805   -57.3448276  13.08333333\n14 -0.02 0.0099920016            NA  -2.91666667\n15  0.19 0.0092910321    -5.3448276  -2.91666667\n16  0.15 0.0006964331    23.6551724  11.08333333\n17  0.19 0.0032148900   -18.3448276   7.08333333\n18  0.02 0.0057097152   -30.3448276  -7.91666667\n19  0.47 0.0085492508            NA  -6.91666667\n20  0.19 0.0046455161     5.6551724  11.08333333\n21  0.33 0.0124071752            NA  -7.91666667\n22  0.06 0.0157589359   -36.3448276  -7.91666667\n23  0.05 0.0033166875            NA   2.08333333\n24  0.24 0.0024877248            NA   5.08333333\n25  0.14 0.0123228738            NA -10.91666667\n26 -0.02 0.0285485760            NA   5.08333333\n27  0.28 0.0066877682            NA  11.08333333\n28  0.14 0.0034825513    35.6551724   9.08333333\n29  0.27 0.0245575546   -42.3448276  -3.91666667\n30  0.38 0.0140779108   -12.3448276 -10.91666667\n31  0.52 0.0212926464            NA  -5.91666667\n32  0.66 0.0127418944    23.6551724  -5.91666667\n33  0.36 0.0303038464    23.6551724  -5.91666667\n34  0.21 0.0042698356    11.6551724  10.08333333\n35  0.19 0.0042231964    11.6551724  10.08333333\n36  0.14 0.0184843108            NA -12.91666667\n37  0.36 0.0102377859    95.6551724  -7.91666667\n38  0.09 0.0006314927    23.6551724  11.08333333\n39  0.16 0.0053946327            NA  13.08333333\n40 -0.07 0.0319427100            NA  -0.91666667\n41  0.36 0.0140295585    89.6551724  -8.91666667\n42  0.36 0.0008270700    95.6551724  -4.91666667\n43  0.22 0.0238300674    -0.3448276   8.08333333\n44  0.04 0.0066899501   -72.3448276   7.08333333\n45  0.06 0.0146001906            NA  -8.91666667\n46  0.41 0.0150447307            NA  -3.91666667\n47  0.04 0.0140394727            NA  -3.91666667\n48  0.23 0.0067954425   -48.3448276   2.08333333\n\n\n\n\n\n#::::: columns #::: {.column width=“40%”} #:::\n#::: {.column width=“60%”} #::: #:::::\n#::: notes #No notes #:::\n#::: aside #Some additional commentary of more peripheral interest. #:::\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 37 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 37 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n#::: panel-tabset ### Tab A\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 37 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 37 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nTab B\nContent for Tab B :::"
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#why-combine-meta-analysis-and-sem",
    "href": "posts/Presentation slides/paper1_presentation.html#why-combine-meta-analysis-and-sem",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Why combine Meta-Analysis and SEM?",
    "text": "Why combine Meta-Analysis and SEM?\nLimitations of Meta-Analysis Alone:\n\nAnalyzes only one effect (e.g., Motivation ↔︎ Information) at a time.\nCannot evaluate multi-variable relationships or mediation effects.\n\nLimitations of SEM Alone:\n\nRequires large sample sizes; low statistical power with small samples.\nOften subject to confirmation bias (limited comparison of alternative models).\nTypically uses cross-sectional data, lacking cross-time reliability.\n\nAdvantages of Combining Meta-Analysis & SEM (MASEM):\n\nIntegrates data across studies for higher statistical power.\nSummarizes complex relationships among multiple variables.\nCompares and integrates multiple models to find the best fit."
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html#approaches-to-masem-analysis",
    "href": "posts/Presentation slides/paper1_presentation.html#approaches-to-masem-analysis",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Approaches to MASEM Analysis",
    "text": "Approaches to MASEM Analysis\nMASEM Process:\n\nIntegrate Correlations via Meta-Analysis:\n\nUse reported correlations or data to form a pooled correlation matrix.\nPreferred over covariance matrix due to scale differences across studies.\n\nFit SEM using Pooled Matrix:\n\nAnalyze relationships and test models.\n\n\nUnivariate Method (Most Popular):\nSteps:\n\nConduct meta-analysis for each pairwise correlation..(its like conducting a separate meta-analysis for each pair of variables).\n\n\nExample: For 5 variables, 10 pairwise correlations are needed.\n\n\nFit SEM with pooled correlation matrix.\n\n\nAdvantages: Simpler, widely used (~95% of MASEM papers).\n\nLimitations\n\nAssumes Independence:\n\nDoes not consider interdependence of correlation coefficients (i.e., ignoring sampling covariance).\n\nCorrelation vs. Covariance:\n\nCorrelation matrix lacks variability information (diagonal always = 1).\nCovariance matrix is richer but less commonly used in univariate methods.\n\nSample Size Controversy:\nVarious suggestions (mean, median, sum, harmonic mean).\nHarmonic mean is often preferred to mitigate excessive sample size influence."
  },
  {
    "objectID": "posts/Presentation slides/paper1_presentation.html",
    "href": "posts/Presentation slides/paper1_presentation.html",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "",
    "text": "Meta-analytic SEM (MASEM) is the integration of two methods: Meta-analysis and Structural equation modeling (SEM).\nWith MASEM, we can explain the relationship between groups of variables across several studies.\nMASEM can be applied in different fields including psychology, education, medicine, …\nAccording to the author, MASEM is not yet very popular thus the need to write the primer."
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#section",
    "href": "posts/meta-analysis/CheungMetaSEM.html#section",
    "title": "CheungMetaSEM",
    "section": "",
    "text": "(A slide with no title)"
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#section-1",
    "href": "posts/meta-analysis/CheungMetaSEM.html#section-1",
    "title": "CheungMetaSEM",
    "section": "",
    "text": "(Another slide with no title)"
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#slide-title",
    "href": "posts/meta-analysis/CheungMetaSEM.html#slide-title",
    "title": "CheungMetaSEM",
    "section": "Slide Title",
    "text": "Slide Title"
  },
  {
    "objectID": "posts/meta-analysis/CheungMetaSEM.html#slide-title-1",
    "href": "posts/meta-analysis/CheungMetaSEM.html#slide-title-1",
    "title": "CheungMetaSEM",
    "section": "Slide Title",
    "text": "Slide Title"
  },
  {
    "objectID": "posts/meta-analysis/Untitled.html",
    "href": "posts/meta-analysis/Untitled.html",
    "title": "Structural Equation Modeling Based Meta-Analysis",
    "section": "",
    "text": "Meta analysis and SEM are usually treated as two different fields\nResearchers with knowledge in one field may be oblivious about the advantages and limitation of the other field.\nThere is more gain when these two methods are combined to develop new statistical methods and application.\nMeta-analysis based SEM is a framework that uses SEM method to conduct meta-analyses where meta-analytic data are modeled.\nconceptualize Meta-Analysis as a SEM.\nExample:\n\n\nTab ATab B\n\n\nSubjects (N subjects)\nIndicators or observed variables\nLatent variables\nMean of the latent variable\nVariance of the latent variable\nKnown variance of measurement error in the ith subject\npredictor or covariates\n\n\nStudies (K studies)\nObserved effect size\nTrue or population effect size\nAverage effect\nHeterogeneity variance\nKnown sampling variance in the ith study\nStudy characteristics, predictor, covariates or moderator\n\n\n\n\nEach ffect size (MA) has its own sampling error just like each subject or individual (SEM) has its own measurement error."
  },
  {
    "objectID": "posts/Presentation slides/CopyOfpres_1.html",
    "href": "posts/Presentation slides/CopyOfpres_1.html",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "",
    "text": "Meta-analytic SEM (MASEM) is the integration of two methods: Meta-analysis and Structural equation modeling (SEM).\nWith MASEM, we can explain the relationship between groups of variables across several studies.\nMASEM can be applied in different fields including psychology, education, medicine, …\nAccording to the author, MASEM is not yet very popular thus the need to write the primer."
  },
  {
    "objectID": "posts/Presentation slides/CopyOfpres_1.html#background",
    "href": "posts/Presentation slides/CopyOfpres_1.html#background",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "",
    "text": "Meta-analytic SEM (MASEM) is the integration of two methods: Meta-analysis and Structural equation modeling (SEM).\nWith MASEM, we can explain the relationship between groups of variables across several studies.\nMASEM can be applied in different fields including psychology, education, medicine, …\nAccording to the author, MASEM is not yet very popular thus the need to write the primer."
  },
  {
    "objectID": "posts/Presentation slides/CopyOfpres_1.html#introduction-to-meta-analysis-ma",
    "href": "posts/Presentation slides/CopyOfpres_1.html#introduction-to-meta-analysis-ma",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Introduction to meta-analysis (MA)",
    "text": "Introduction to meta-analysis (MA)\n\nMA refers is a set of statistical procedure used to synthesize research findings (quantitative data) from multiple studies for the purpose of obtaining a conclusion about the research question.\nAccording to Glass, whether the analysis is referred to as a primary, secondary or meta-analysis dependents on how the data was analyzed.\nWhen primary data collected (first time) by the researcher for a particular study and is analyzed - primary analysis.\nWhen the primary data is re-analyzed by another researcher for a study, the data then becomes a secondary data and the analysis is a secondary analysis.\nmeta-analysis integrates a number of independent studies and combines these independent studies by statistical means to get a comprehensive result.\nSmith and Glass were the earliest psychologist in the field of social science to employ meta-analysis. They analyzed 375 research results on whether psychotherapy was effective for patients. They concluded that almost no difference existed in the effects of different psychotherapy methods - effective."
  },
  {
    "objectID": "posts/Presentation slides/CopyOfpres_1.html#introduction-to-sem",
    "href": "posts/Presentation slides/CopyOfpres_1.html#introduction-to-sem",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Introduction to SEM",
    "text": "Introduction to SEM\n\nSEM is a statistical method that integrates regression analysis, factor analysis and path analysis.\npath analysis was proposed by Wright in 1920, Spearman put forward factor analysis in 1904\nPath analysis examines the complicated relationship between observed variables. So path analysis can be regarded as a special SEM analysis.\nSEM is a confirmatory statistical method that thrives on rigorous theoretical support in the form of an hypothesized model. With SEM the hypothesized model is fit to data\nCompared with path analysis, SEM can simultaneously estimate the measurement indicators, latent variables, error of measurement indicators, and validity of measurement.\nSEM can be conducted if;\n\nthe data is multivariate normal\nthe sample size and the covariance matrix (that shows the relationship between variables) is provided."
  },
  {
    "objectID": "posts/Presentation slides/CopyOfpres_1.html#why-combine-meta-analysis-and-sem",
    "href": "posts/Presentation slides/CopyOfpres_1.html#why-combine-meta-analysis-and-sem",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Why combine Meta-Analysis and SEM?",
    "text": "Why combine Meta-Analysis and SEM?\n\nLimitations of Meta-Analysis Alone:\n\nAnalyzes only one effect (e.g., Motivation ↔︎ Information) at a time.\nCannot evaluate multi-variable relationships or mediation effects.\n\n\n\nLimitations of SEM Alone:\n\nRequires large sample sizes; low statistical power with small samples.\nOften subject to confirmation bias (limited comparison of alternative models).\nTypically uses cross-sectional data, lacking cross-time reliability.\n\n\n\nAdvantages of Combining Meta-Analysis & SEM (MASEM):\n\nIntegrates data across studies for higher statistical power.\nSummarizes complex relationships among multiple variables.\nCompares and integrates multiple models to find the best fit.\n\n\n\n\nUnique Benefits of MASEM\n\nOvercomes Data Gaps:\n\nEstimates relationships between variables not included together in primary studies.\n\nExample:\n\nStudy 1: Correlation (A ↔︎ B).\nStudy 2: Correlation (B ↔︎ C).\nStudy 3: Correlation (A ↔︎ C).\nMASEM: Estimates the full A ↔︎ B ↔︎ C relationship.\n\nReliability Across Time:\n\nCombines studies with different time frames for robust, cross-time results.\n\nComplexity Handling:\n\nSimultaneously analyzes multiple variable relationships and mediating effects."
  },
  {
    "objectID": "posts/Presentation slides/CopyOfpres_1.html#approaches-to-masem-analysis",
    "href": "posts/Presentation slides/CopyOfpres_1.html#approaches-to-masem-analysis",
    "title": "Meta-analytic structural equation modeling: a primer",
    "section": "Approaches to MASEM Analysis",
    "text": "Approaches to MASEM Analysis\n\nMASEM Process:\n\nIntegrate Correlations via Meta-Analysis:\n\nUse reported correlations or data to form a pooled correlation matrix.\nPreferred over covariance matrix due to scale differences across studies.\n\nFit SEM using Pooled Matrix:\n\nAnalyze relationships and test models.\n\n\n\n\nUnivariate Method (Most Popular):\n\nSteps:\n\nConduct meta-analysis for each pairwise correlation..(its like conducting a separate meta-analysis for each pair of variables).\n\n\nExample: For 5 variables, 10 pairwise correlations are needed.\n\n\nFit SEM with pooled correlation matrix.\n\n\nAdvantages: Simpler, widely used (~95% of MASEM papers).\n\n\n\nLimitations\n\nAssumes Independence:\n\nDoes not consider interdependence of correlation coefficients (i.e., ignoring sampling covariance).\n\nCorrelation vs. Covariance:\n\nCorrelation matrix lacks variability information (diagonal always = 1).\nCovariance matrix is richer but less commonly used in univariate methods.\n\nSample Size Controversy:\nVarious suggestions (mean, median, sum, harmonic mean).\nHarmonic mean is often preferred to mitigate excessive sample size influence.\n\n\n\n\n\nMultivariate approach\n\nCorrects the limitations of the univariates approach.\nCorrelation coefficients for all pairs of variables across studies are analyzed at once to obtain a pooled correlation matrix.\nThe pooled matrix is used to fit the SEM.\nIf we assume a random-effects model, we need to estimate the between study co(variance) \\(\\boldsymbol{\\tau^2}_\\rho\\) (aka.. heterogeneity matrix— \\(\\boldsymbol{\\tau^2}_\\rho = var(u_i)\\)\nIn practice, the covariances are fixed to zero, while the variances are estimated.\n\\[\\boldsymbol{r}_i = \\boldsymbol{\\rho}_R + \\boldsymbol{u_i} + \\boldsymbol{e_i}\\] (1)\n\n\\(\\boldsymbol{r}_i\\) = sample correlation vector (lower part of the matrix).\n\\(\\boldsymbol{\\rho}_R\\) = population correlation vector.\n\\(\\boldsymbol{u_i}\\) = random effects vector (we don’t know this, thus we need to estimate it).\n\\(\\boldsymbol{e_i}\\) = error variance vector (used to measure the sampling error).\n\nIf we assume that there is no heterogeneity among the studies, a fixed-effect model is adopted.\n\\[\\boldsymbol{r}_i = \\boldsymbol{\\rho}_R + \\boldsymbol{e_i}\\] (2)\nQ-statistics is used to test the heterogeneity of covariance matrices across studies.\n\n\n\nGLS method\n\nIntegrates the correlation matrices across studies using traditional meta-analysis, and then fits the SEM to data.\n\n\n\nlimitations of GLS method\n\nIt can only fit traditional regression model.\nIf path or factor analysis were to be carried out, we will need to insert the pooled correlation matrix into the SEM software for analysis.\nThis method cannot provide an accurate sample size to the model.\nIt does not take account of the variation of inter-study sampling .\nSome of the limitations of the GLS can be corrected using the Two-stage approach.\n\n\n\n\nTwo-Stage SEM (TSSEM)\n\nProposed by Cheung and Chan (2005)\nUnlike the GLS approach, TSSEM approach uses SEM in both stages (integrating the data and fitting the model).\nTSSEM applies Maximum Likelihood (ML) to obtain the pooled correlation matrix and the heterogeneity test.\nEach study is referred to as a group\nThe approach is useful because of its accuracy in estimation compared to other methods(GLS) and robustness in handling missing data.\n\n\n\nSteps in TSSEM:\n\nStage 1:\n\nIntegrate Correlation Matrix:\n\nFit a multi-group SEM is used to estimate the population correlation matrix \\(\\boldsymbol{R}\\) of p variables.\nUse selection matrix \\(\\boldsymbol{X_i}\\) to handle missing variables (has a variance of 1 in the diagonal).\n\nThe model of each group (study) is: \\(\\boldsymbol{\\sum_i} = \\boldsymbol{D_i} (\\boldsymbol{X_i} \\boldsymbol{R} \\boldsymbol{X_i})\\boldsymbol{D_i}\\) (3)\n\n\\(\\boldsymbol{\\sum_i}\\) = population covariance matrix.\n\\(\\boldsymbol{D_i}\\) = diagonal matrix of standard deviation.\n\\(\\boldsymbol{X_i}\\) = selection matrix that has 0s and 1s as the elements.\n\\(\\boldsymbol{R}\\) = correlation matrix in the i_th study.\n\nfitting the above model, we can estimate the value of the population correlation coefficient and the asymptotic variance matrix.\nthe above model is fitted under the assumption that all studies have the same correlation coefficients.\nWhen the assumption is relaxed (i.e the studies have different correlation coefficients \\(\\boldsymbol{R}\\)), then \\(\\boldsymbol{X_i}\\) is no longer needed, and the saturated model is rewritten as:\n\n\\(\\boldsymbol{\\sum_i} = \\boldsymbol{D_i} \\boldsymbol{R} \\boldsymbol{D_i}\\) (4)\n\nTest heterogeneity using chi-square difference between restricted (homogeneous) and saturated models. If \\(\\chi^2\\) test is significant, we reject the null hypothesis of homogeneity among studies.\n\n\n\n\nStage 2:\n\nUse the pooled correlation matrix \\(\\boldsymbol{R}\\) estimated in the first stage to fit Structural Equation Model.\nAlongside \\(\\boldsymbol{R}\\), asymptotic co(variance) matrix is obtained in the first. stage\nUse Weighted Least Squares (WLS) with the pooled correlation matrix \\(\\boldsymbol{R}\\). and its asymptotic variance-covariance matrix \\(\\boldsymbol{V}\\).\n\\({F}\\_wls = (\\boldsymbol{r} - \\boldsymbol{r}\\_model)^T {V}^-1 (\\boldsymbol{r} - \\boldsymbol{r}\\_model)\\)\n\n\\(\\boldsymbol{r}\\) = vector containing the lower triangular element of the sample correlation matrix\n\\(\\boldsymbol{r}\\_model\\) = vector containing the lower triangular element of the implied covariance matrix\n\\({V}^-1\\) = the asymptotic covariance matrix from the first stage."
  },
  {
    "objectID": "posts/meta-analysis/Untitled.html#intro",
    "href": "posts/meta-analysis/Untitled.html#intro",
    "title": "Structural Equation Modeling Based Meta-Analysis",
    "section": "Intro",
    "text": "Intro\nSeparation of SEM and Meta-Analysis\n\nTraditionally treated as distinct fields in textbooks, software, training, and journals.\nResearchers may not be aware of benefits and techniques from the other area.\n\n####Integration of Meta-Analysis into SEM\n\nOffers new research opportunities for statistical methods and applications.\nSEM provides a flexible framework for modeling meta-analytic data.\n\nConceptualization of Meta-Analysis as SEM\n\nTreats studies in a meta-analysis as subjects in SEM.\nObserved effect sizes correspond to observed variables; population (true) effect sizes correspond to latent variables.\nMean and variance of effect sizes equate to average effect and heterogeneity variance in meta-analysis.\nSampling variance is analogous to measurement error in SEM.\nStudy characteristics (covariates) can predict effect sizes in cases of excess heterogeneity.\nStudy characteristics are referred to as covariates (instead of moderators) to avoid confusion.\nEach ffect size (MA) has its own sampling error just like each subject or individual (SEM) has its own measurement error."
  },
  {
    "objectID": "posts/meta-analysis/Untitled.html#effect-sizes",
    "href": "posts/meta-analysis/Untitled.html#effect-sizes",
    "title": "Structural Equation Modeling Based Meta-Analysis",
    "section": "EFfect sizes",
    "text": "EFfect sizes\n\nprimary data in meta analysis.\n\n\n\n\nNduka Boika"
  },
  {
    "objectID": "posts/meta-analysis/Untitled.html#effect-sizes-in-meta-analysis",
    "href": "posts/meta-analysis/Untitled.html#effect-sizes-in-meta-analysis",
    "title": "Structural Equation Modeling Based Meta-Analysis",
    "section": "EFfect sizes in Meta-Analysis",
    "text": "EFfect sizes in Meta-Analysis\n\nprimary data in meta analysis.\nRepresents the magnitude of a phenomenon in quantitative terms.\nCan be standardized (e.g., Cohen’s d, correlation coefficient) or unstandardized (e.g., raw mean difference).\nThe generic effect-size for each study i is notated as \\(y_i\\) and is represented as:\n                        $$y_i = f_i + e_i$$\n                      $y_i$ = sample (observed) effect size for the ith study\n                      $f_i$ = population (true) effect size\n                      $e_i$ = error term in the observed effect-size\n                      $var(e_i)$ = a.k.a $v_i$ sampling variance (usually known in MA)\n\nChoosing Appropriate Effect Sizes\n\nEffect sizes should clearly indicate direction; variance-explained metrics (e.g \\(R^2, \\eta^2, \\Omega^2\\) are rarely used.\nSmall Sample Bias: Some estimators (e.g., standardized mean difference, SMD) are biased in small samples. Correction factors (e.g., Hedges’ correction) may be applied.\nDistributional Assumption: Effect sizes are assumed to follow a normal distribution, but they only approximate normality asymptotically, requiring a reasonable sample size.\nVariance Stabilizing Transformations:\n\nLog transformation for Relative Risk (RR) and Odds Ratio (OR).\nFisher’s z-transformation for correlation coefficients to normalize distributions.\n\n\n\n\n\nNduka Boika"
  },
  {
    "objectID": "multi.html",
    "href": "multi.html",
    "title": "Structural Equation Modeling Based Meta-Analysis - multivarate",
    "section": "",
    "text": "When the research questions become more complicated, a single effect-size may not be sufficient to summarize the effect in the pry studies. Multiple effect sizes are required to quantify the effects of the study.\nAn extension of the univariate approach\nThe data for the analysis is the form of a vector or matrix\nstill the same convention as the univariate approach in terms of:\n\nsources of dependency (variation)\n\nfrom the samples in the primary study (sampling variance) in form of the covariance matrix - which is already known from the primary study.\nbetween study dependence which is represented by the between study variance component \\((\\tau^2)\\).\n\nit is assumed that the true effects-sizes between the studies maybe correlated.\ngiven one study, it is difficult to estimate this dependence"
  },
  {
    "objectID": "multi.html#multivariate-approach",
    "href": "multi.html#multivariate-approach",
    "title": "Structural Equation Modeling Based Meta-Analysis - multivarate",
    "section": "",
    "text": "When the research questions become more complicated, a single effect-size may not be sufficient to summarize the effect in the pry studies. Multiple effect sizes are required to quantify the effects of the study.\nAn extension of the univariate approach\nThe data for the analysis is the form of a vector or matrix\nstill the same convention as the univariate approach in terms of:\n\nsources of dependency (variation)\n\nfrom the samples in the primary study (sampling variance) in form of the covariance matrix - which is already known from the primary study.\nbetween study dependence which is represented by the between study variance component \\((\\tau^2)\\).\n\nit is assumed that the true effects-sizes between the studies maybe correlated.\ngiven one study, it is difficult to estimate this dependence"
  },
  {
    "objectID": "multi.html#multivariate-ffect-size-equations",
    "href": "multi.html#multivariate-ffect-size-equations",
    "title": "Structural Equation Modeling Based Meta-Analysis - multivarate",
    "section": "Multivariate ffect-size equations",
    "text": "Multivariate ffect-size equations\n\nMASEM combines the ideas of MA and SEM\nTest Structural Equation models on the pooled correlation (covariance) matrix\nTwo stages (TSSEM)\n\npool the correlation matrix together\npooled correlation matrix is used to fit the SEM\n\nThe metaSEM package handles both fixed- or random-effects models automatically.\nTSSEM uses Maximum Likelihood (ML) to obtain the pooled correlation matrix and the heterogeneity test for both the fixed- and random- effects model.\nThe parameter estimates are unbiased\neffective when correlation estimates are MCAR or MAR.\n\n###Fixed-effects model - Assumes common population (covariance) correlation matrices for all studies - If an ith study has a covariance matrix, the matrix can be decomposed into a product of the matrices of correlations and standard deviations. \\(\\boldsymbol{\\sum_i}(\\theta) = \\boldsymbol{D_i} \\boldsymbol{\\rho_i} \\boldsymbol{D_i}\\) \\(\\boldsymbol{\\sum_i}\\) = model implied covariance matrix. \\(\\boldsymbol{D_i}\\) = diagonal matrix of standard deviations. \\(\\boldsymbol{\\rho_i}\\) = correlation matrix in the i_th study. - A constraint is imposed such that \\(\\boldsymbol{\\rho} = \\boldsymbol{\\rho_1}=\\boldsymbol{\\rho_2}=\\boldsymbol{\\rho_3}...=\\boldsymbol{\\rho_k}\\) - \\(\\boldsymbol{D_i}\\) may vary across studies"
  }
]